for i in $(seq 1 1 5); do
    java -Xmx4608m -cp parallel-kendalls-tau-1.0-SNAPSHOT.jar:lib/* gr.archimedesai.centralized.MainArray data/ookla-small.csv 0 2 , timeExec-knight-ookla.txt
done

for i in $(seq 1 1 5); do
    java -Xmx4608m -cp parallel-kendalls-tau-1.0-SNAPSHOT.jar:lib/* gr.archimedesai.centralized.MainArray data/taxi-small.csv 0 2 , timeExec-knight-taxi.txt
done

for i in $(seq 1 1 5); do
    java -Xmx4608m -cp parallel-kendalls-tau-1.0-SNAPSHOT.jar:lib/* gr.archimedesai.centralized.MainArray data/weather-small.csv 0 2 , timeExec-knight-weather.txt
done

for i in $(seq 1 1 5); do
    java -Xmx4608m -cp parallel-kendalls-tau-1.0-SNAPSHOT.jar:lib/* gr.archimedesai.centralized.MainArray data/radiation-small.csv 0 2 , timeExec-knight-radiation.txt
done



for j in $(seq 1 1 5); do
    for i in 25 50 100 200 400; do
        java -Xmx4608m -cp parallel-kendalls-tau-1.0-SNAPSHOT.jar:lib/* gr.archimedesai.centralized.MainGrid data/ookla-small.csv 0 2 , 1.0 0.0 3932585.1 39598.1 "$i" "$i" timeExec-gridRegular-ookla${j}.txt
    done

    for i in 25 50 100 200 400; do
        java -Xmx4608m -cp parallel-kendalls-tau-1.0-SNAPSHOT.jar:lib/* gr.archimedesai.centralized.MainGrid data/taxi-small.csv 0 2 , 0.0 0.0 6.40172993E8 861611.06 "$i" "$i" timeExec-gridRegular-taxi${j}.txt
    done

    for i in 25 50 100 200 400; do
        java -Xmx4608m -cp parallel-kendalls-tau-1.0-SNAPSHOT.jar:lib/* gr.archimedesai.centralized.MainGrid data/weather-small.csv 0 2 , -115.0 0.0 141.1 100.1 "$i" "$i" timeExec-gridRegular-weather${j}.txt
    done

    for i in 25 50 100 200 400; do
        java -Xmx4608m -cp parallel-kendalls-tau-1.0-SNAPSHOT.jar:lib/* gr.archimedesai.centralized.MainGrid data/radiation-small.csv 0 2 , 3.5 0.0 99.1 1351.1 "$i" "$i" timeExec-gridRegular-radiation${j}.txt
    done
done

for j in $(seq 1 1 5); do
    for i in 25 50 100 200 400; do
        java -Xmx4608m -cp parallel-kendalls-tau-1.0-SNAPSHOT.jar:lib/* gr.archimedesai.centralized.MainAdaptiveGrid data/ookla-small.csv 0 2 , 1.0 0.0 3932585.1 39598.1 "$i" "$i" timeExec-gridAdaptive-ookla${j}.txt data/samples/ookla-small.csv
    done

    for i in 25 50 100 200 400; do
        java -Xmx4608m -cp parallel-kendalls-tau-1.0-SNAPSHOT.jar:lib/* gr.archimedesai.centralized.MainAdaptiveGrid data/taxi-small.csv 0 2 , 0.0 0.0 6.40172993E8 861611.06 "$i" "$i" timeExec-gridAdaptive-taxi${j}.txt data/samples/taxi-small.csv
    done

    for i in 25 50 100 200 400; do
        java -Xmx4608m -cp parallel-kendalls-tau-1.0-SNAPSHOT.jar:lib/* gr.archimedesai.centralized.MainAdaptiveGrid data/weather-small.csv 0 2 , -115.0 0.0 141.1 100.1 "$i" "$i" timeExec-gridAdaptive-weather${j}.txt data/samples/weather-small.csv
    done

    for i in 25 50 100 200 400; do
        java -Xmx4608m -cp parallel-kendalls-tau-1.0-SNAPSHOT.jar:lib/* gr.archimedesai.centralized.MainAdaptiveGrid data/radiation-small.csv 0 2 , 3.5 0.0 99.1 1351.1 "$i" "$i" timeExec-gridAdaptive-radiation${j}.txt data/samples/radiation-small.csv
    done
done



for j in $(seq 1 1 5); do
    for i in 25 50 100 200 400; do
        spark-submit --class gr.archimedesai.distributed.Main --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 5g --num-executors 12 --conf spark.network.timeout=600s parallel-kendalls-tau-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/kendall-tau/ookla-small.csv 0 2 , 1.0 0.0 3932585.1 39598.1 "$i" "$i" timeExec-gridRegular-distributed-ookla${j}.txt 192
    done

    for i in 25 50 100 200 400; do
        spark-submit --class gr.archimedesai.distributed.Main --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 5g --num-executors 12 --conf spark.network.timeout=600s parallel-kendalls-tau-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/kendall-tau/taxi-small.csv 0 2 , 0.0 0.0 6.40172993E8 861611.06 "$i" "$i" timeExec-gridRegular-distributed-taxi${j}.txt 192
    done

    for i in 25 50 100 200 400; do
        spark-submit --class gr.archimedesai.distributed.Main --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 5g --num-executors 12 --conf spark.network.timeout=600s parallel-kendalls-tau-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/kendall-tau/weather-small.csv 0 2 , -115.0 0.0 141.1 100.1 "$i" "$i" timeExec-gridRegular-distributed-weather${j}.txt 192
    done

    for i in 25 50 100 200 400; do
        spark-submit --class gr.archimedesai.distributed.Main --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 5g --num-executors 12 --conf spark.network.timeout=600s parallel-kendalls-tau-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/kendall-tau/radiation-small.csv 0 2 , 3.5 0.0 99.1 1351.1 "$i" "$i" timeExec-gridRegular-distributed-radiation${j}.txt 192
    done
done

for j in $(seq 1 1 5); do
    for i in 25 50 100 200 400; do
        spark-submit --class gr.archimedesai.distributed.MainAdaptive --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 5g --num-executors 12 --conf spark.network.timeout=600s parallel-kendalls-tau-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/kendall-tau/ookla-small.csv 0 2 , 1.0 0.0 3932585.1 39598.1 "$i" "$i" timeExec-gridAdaptive-distributed-ookla${j}.txt 192 data/samples/ookla-small.csv
    done

    for i in 25 50 100 200 400; do
        spark-submit --class gr.archimedesai.distributed.MainAdaptive --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 5g --num-executors 12 --conf spark.network.timeout=600s parallel-kendalls-tau-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/kendall-tau/taxi-small.csv 0 2 , 0.0 0.0 6.40172993E8 861611.06 "$i" "$i" timeExec-gridAdaptive-distributed-taxi${j}.txt 192 data/samples/taxi-small.csv
    done

    for i in 25 50 100 200 400; do
        spark-submit --class gr.archimedesai.distributed.MainAdaptive --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 5g --num-executors 12 --conf spark.network.timeout=600s parallel-kendalls-tau-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/kendall-tau/weather-small.csv 0 2 , -115.0 0.0 141.1 100.1 "$i" "$i" timeExec-gridAdaptive-distributed-weather${j}.txt 192 data/samples/weather-small.csv
    done

    for i in 25 50 100 200 400; do
        spark-submit --class gr.archimedesai.distributed.MainAdaptive --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 5g --num-executors 12 --conf spark.network.timeout=600s parallel-kendalls-tau-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/kendall-tau/radiation-small.csv 0 2 , 3.5 0.0 99.1 1351.1 "$i" "$i" timeExec-gridAdaptive-distributed-radiation${j}.txt 192 data/samples/radiation-small.csv
    done
done




ookla:      1.0 0.0 3932585.1 39598.1

taxi:     0.0 0.0 6.40172993E8 861611.06

weather:  -115.0 0.0 141.1 100.1


radiation:     3.5 0.0 99.1 1351.1




weather: -116.0 0.0 143.1 100.1
taxi: 0.0 0.0 7.5223897E9 1.0000017E7



for j in $(seq 1 1 5); do
    for i in 1 2 3 4; do
        spark-submit --class gr.archimedesai.distributed.MainAdaptive --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 5g --num-executors 12 --conf spark.network.timeout=600s parallel-kendalls-tau-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/kendall-tau/taxi-f${i}.csv 0 2 , 0.0 0.0 7.5223897E9 1.0000017E7 200 200 timeExec-gridAdaptive-distributed-taxi-f${i}.txt 192 data/samples/taxi-f${i}.csv
    done
done

for j in $(seq 1 1 5); do
    for i in 1 2 3; do
        spark-submit --class gr.archimedesai.distributed.MainAdaptive --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 5g --num-executors 12 --conf spark.network.timeout=600s parallel-kendalls-tau-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/kendall-tau/weather-f${i}.csv 0 2 , -116.0 0.0 143.1 100.1 200 200 timeExec-gridAdaptive-distributed-weather-f${i}.txt 192 data/samples/weather-f${i}.csv
    done
done


for j in $(seq 1 1 5); do
    for i in 3 6 9; do
        spark-submit --class gr.archimedesai.distributed.MainAdaptive --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 5g --num-executors "$i" --conf spark.network.timeout=600s parallel-kendalls-tau-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/kendall-tau/taxi-f1.csv 0 2 , 0.0 0.0 7.5223897E9 1.0000017E7 200 200 timeExec-gridAdaptive-distributed-executors${i}-taxi-f1.txt 192 data/samples/taxi-f1.csv
        spark-submit --class gr.archimedesai.distributed.MainAdaptive --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 5g --num-executors "$i" --conf spark.network.timeout=600s parallel-kendalls-tau-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/kendall-tau/weather-f1.csv 0 2 , -116.0 0.0 143.1 100.1 200 200 timeExec-gridAdaptive-distributed-executors${i}-weather-f1.txt 192 data/samples/weather-f1.csv
    done
done






for j in $(seq 1 1 5); do
    for i in 3 6 9; do
        spark-submit --class gr.archimedesai.distributed.Main --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 5g --num-executors "$i" --conf spark.network.timeout=600s parallel-kendalls-tau-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/kendall-tau/weather-f1.csv 0 2 , -116.0 0.0 143.1 100.1 200 200 timeExec-gridRegular-distributed-executors${i}-weather-f1.txt 192
    done
done


---- sampling ----

for j in $(seq 1 1 5); do
    for i in 1 2 3; do
        spark-submit --class gr.archimedesai.distributed.MainAdaptive --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 5g --num-executors 12 --conf spark.network.timeout=600s parallel-kendalls-tau-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/kendall-tau/sierpinski.csv 0 1 , 0 0 1 1 200 200 timeExec-gridAdaptive-distributed-sierpinski-sample-${i}.txt 192 data/samples/sierpinski-sample-${i}.csv
    done

    for i in 1 2 3; do
        spark-submit --class gr.archimedesai.distributed.MainAdaptive --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 5g --num-executors 12 --conf spark.network.timeout=600s parallel-kendalls-tau-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/kendall-tau/gaussian.csv 0 1 , 0 0 1 1 200 200 timeExec-gridAdaptive-distributed-gaussian-sample-${i}.txt 192 data/samples/gaussian-sample-${i}.csv
    done
done


for j in $(seq 1 1 5); do
    for i in 1 2 3; do
        spark-submit --class gr.archimedesai.distributed.MainAdaptive --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 5g --num-executors 12 --conf spark.network.timeout=600s parallel-kendalls-tau-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/kendall-tau/taxi-small.csv 0 2 , 0.0 0.0 6.40172993E8 861611.06 200 200 timeExec-gridAdaptive-distributed-taxi-sample-${i}.txt 192 data/samples/taxi-small-sample-${i}.csv
    done

    for i in 1 2 3; do
        spark-submit --class gr.archimedesai.distributed.MainAdaptive --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 5g --num-executors 12 --conf spark.network.timeout=600s parallel-kendalls-tau-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/kendall-tau/weather-small.csv 0 2 , -115.0 0.0 141.1 100.1 200 200 timeExec-gridAdaptive-distributed-weather-sample-${i}.txt 192 data/samples/weather-small-sample-${i}.csv
    done
done

for j in $(seq 1 1 5); do
    for i in 1 2 3; do
        java -Xmx4608m -cp parallel-kendalls-tau-1.0-SNAPSHOT.jar:lib/* gr.archimedesai.centralized.MainAdaptiveGrid data/sierpinski.csv 0 1 , 0 0 1 1 50 50 timeExec-gridAdaptive-sierpinski-sample-${i}.txt data/samples/sierpinski-sample-${i}.csv
    done

    for i in 1 2 3; do
        java -Xmx4608m -cp parallel-kendalls-tau-1.0-SNAPSHOT.jar:lib/* gr.archimedesai.centralized.MainAdaptiveGrid data/gaussian.csv 0 1 , 0 0 1 1 50 50 timeExec-gridAdaptive-gaussian-sample-${i}.txt data/samples/gaussian-sample-${i}.csv
    done
done

for j in $(seq 1 1 5); do
    for i in 1 2 3; do
        java -Xmx4608m -cp parallel-kendalls-tau-1.0-SNAPSHOT.jar:lib/* gr.archimedesai.centralized.MainAdaptiveGrid data/taxi-small.csv 0 2 , 0.0 0.0 6.40172993E8 861611.06 50 50 timeExec-gridAdaptive-taxi-sample-${i}.txt data/samples/taxi-small-sample-${i}.csv
    done

    for i in 1 2 3; do
        java -Xmx4608m -cp parallel-kendalls-tau-1.0-SNAPSHOT.jar:lib/* gr.archimedesai.centralized.MainAdaptiveGrid data/weather-small.csv 0 2 , -115.0 0.0 141.1 100.1 50 50 timeExec-gridAdaptive-weather-sample-${i}.txt data/samples/weather-small-sample-${i}.csv
    done
done
